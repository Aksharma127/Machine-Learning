{"cells":[{"cell_type":"markdown","metadata":{"id":"UIMfY34UOKur"},"source":["25DLS037_AKSHIT_SHARMA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Zw5s2_cOKuu"},"outputs":[],"source":["# Q1. Load a Transformer Model and Tokenizer\n","from transformers import BertTokenizer, BertModel\n","\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertModel.from_pretrained(model_name)\n","\n","# Print model name and total number of parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Model Name: {model_name}\")\n","print(f\"Total Parameters: {total_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjG3nkXDOKuw"},"outputs":[],"source":["# Q2. Simple Summarization using T5\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# Load T5 model and tokenizer\n","t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n","t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","\n","text = \"Natural Language Processing is a part of Artificial Intelligence that focuses on interaction between computers and human language. It enables applications like chatbots, translation, and summarization.\"\n","input_text = \"summarize: \" + text\n","inputs = t5_tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n","summary_ids = t5_model.generate(inputs, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n","summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","print(\"Summarized Output:\")\n","print(summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERsVqokSOKux"},"outputs":[],"source":["# Q3. Print Number of Layers and Attention Heads in BERT\n","bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n","num_layers = bert_model.config.num_hidden_layers\n","num_heads = bert_model.config.num_attention_heads\n","print(f\"Total Encoder Layers: {num_layers}\")\n","print(f\"Attention Heads per Layer: {num_heads}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKfZP4nxOKuy"},"outputs":[],"source":["# Q4. Tokenize and Decode a Sentence using BERT Tokenizer\n","sentence = \"Transformers make NLP tasks easier.\"\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","tokens = bert_tokenizer.tokenize(sentence)\n","token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n","print(\"Token IDs:\", token_ids)\n","print(\"Decoded Tokens:\", tokens)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}