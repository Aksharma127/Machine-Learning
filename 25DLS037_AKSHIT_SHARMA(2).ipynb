{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyOIqeirv/lzkx0VZ2MJHuwt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModelForMaskedLM\n","\n","print(\"\\nðŸ”¹ Task 1: Completing a sentence\")\n","text_gen = pipeline(\"text-generation\", model=\"gpt2\")\n","start_text = \"The future of AI is\"\n","completion = text_gen(start_text, max_new_tokens=30)\n","print(\" Completed Sentence:\", completion[0]['generated_text'])\n","\n","print(\"\\nðŸ”¹ Task 2: Exploring creativity levels\")\n","low_temp = text_gen(start_text, max_new_tokens=30, temperature=0.2)\n","print(\"\\n Conservative Output:\")\n","print(low_temp[0]['generated_text'])\n","\n","high_temp = text_gen(start_text, max_new_tokens=30, temperature=1.0)\n","print(\"\\n Creative Output:\")\n","print(high_temp[0]['generated_text'])\n","\n","print(\"\\nðŸ”¹ Task 3: Guessing the missing word\")\n","mask_filler = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n","masked_sentence = \"The capital of India is [MASK].\"\n","predictions = mask_filler(masked_sentence, top_k=2)\n","\n","print(\" Top Predictions:\")\n","for i, guess in enumerate(predictions, 1):\n","    print(f\"{i}. {guess['sequence']} (Confidence: {guess['score']:.2f})\")\n","\n","print(\"\\nðŸ”¹ Task 4: Simulating a tool request\")\n","tool_output = {\n","    \"function\": \"get_weather\",\n","    \"arguments\": {\n","        \"city\": \"Delhi\"\n","    }\n","}\n","print(\" Tool Call Format:\")\n","print(tool_output)\n","\n","# Model inspection\n","print(\"\\nðŸ”¹ Task 5: Looking under the hood\")\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total parameters in the model: {total_params:,}\")\n","\n","print(\"\\n Model Details:\")\n","print(model.config)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkROV-v4aOob","executionInfo":{"status":"ok","timestamp":1748881034641,"user_tz":-330,"elapsed":19773,"user":{"displayName":"Akshit Sharma","userId":"08667315936890293680"}},"outputId":"071adffa-52ed-444e-8fa6-99a94cff8cd2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Task 1: Completing a sentence\n"]},{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" Completed Sentence: The future of AI is to develop a world in which we can create a better and more resilient AI. That world is AI.\n","\n","It will be possible to have AI\n","\n","ðŸ”¹ Task 2: Exploring creativity levels\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Conservative Output:\n","The future of AI is going to be a lot more complex than we think.\n","\n","\"We're going to see a lot of things that are going to be very interesting\n","\n"," Creative Output:\n","The future of AI is going to be better than we thought it would be, so maybe we can take a really short time to work on that,\" she said at the conference\n","\n","ðŸ”¹ Task 3: Guessing the missing word\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":[" Top Predictions:\n","1. the capital of india is mumbai. (Confidence: 0.18)\n","2. the capital of india is delhi. (Confidence: 0.15)\n","\n","ðŸ”¹ Task 4: Simulating a tool request\n"," Tool Call Format:\n","{'function': 'get_weather', 'arguments': {'city': 'Delhi'}}\n","\n","ðŸ”¹ Task 5: Looking under the hood\n","Total parameters in the model: 124,439,808\n","\n"," Model Details:\n","GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.52.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}]}]}