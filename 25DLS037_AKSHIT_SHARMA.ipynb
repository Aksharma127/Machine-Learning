{"cells":[{"cell_type":"markdown","id":"e1fe49be","metadata":{"id":"e1fe49be"},"source":["# Week1-Day5 Assignment\n","**Name:** Akshit Sharma  \n","**Roll No.:** 25DLS037"]},{"cell_type":"markdown","source":["##Task 1 (5 Marks) – TensorFlow (Keras backend):"],"metadata":{"id":"eKE4m5A-qF4o"},"id":"eKE4m5A-qF4o"},{"cell_type":"code","execution_count":1,"id":"12d77abf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12d77abf","executionInfo":{"status":"ok","timestamp":1748280976686,"user_tz":-330,"elapsed":14027,"user":{"displayName":"Akshit Sharma","userId":"08667315936890293680"}},"outputId":"675802ef-b2f3-4af3-e747-dd068d9dcf13"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow\n","z: [[-1.9999999]]\n","sigmoid(z): [[0.11920293]]\n","Binary Cross-Entropy Loss: [[2.1269271]]\n"]}],"source":["import tensorflow as tf\n","\n","# Input (manually set)\n","X = tf.constant([[0.5, -1.5, 2.0]], dtype=tf.float32)\n","\n","# Manually setting weights and bias\n","W = tf.Variable([[0.2], [0.8], [-0.5]], dtype=tf.float32)\n","b = tf.Variable(0.1, dtype=tf.float32)\n","\n","# z = XW + b\n","z = tf.matmul(X, W) + b\n","\n","# Sigmoid activation\n","a = tf.math.sigmoid(z)\n","\n","# True label\n","y_true = tf.constant([[1.0]], dtype=tf.float32)\n","\n","# Manually calculating Binary Cross-Entropy Loss\n","epsilon = 1e-7\n","loss = -(y_true * tf.math.log(a + epsilon) + (1 - y_true) * tf.math.log(1 - a + epsilon))\n","\n","print(\"TensorFlow\")\n","print(\"z:\", z.numpy())\n","print(\"sigmoid(z):\", a.numpy())\n","print(\"Binary Cross-Entropy Loss:\", loss.numpy())"]},{"cell_type":"markdown","source":["##Task 2 (5 Marks) – PyTorch:"],"metadata":{"id":"XHv5-yIxp6a7"},"id":"XHv5-yIxp6a7"},{"cell_type":"code","execution_count":2,"id":"77eb9dda","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77eb9dda","executionInfo":{"status":"ok","timestamp":1748280984602,"user_tz":-330,"elapsed":7906,"user":{"displayName":"Akshit Sharma","userId":"08667315936890293680"}},"outputId":"2a1e8145-4fd6-422e-8cd2-da53fccf754a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","PyTorch\n","z: [[-1.9999999]]\n","sigmoid(z): [[0.11920293]]\n","Binary Cross-Entropy Loss: 2.126927137374878\n","Gradients for W: tensor([[-0.4404],\n","        [ 1.3212],\n","        [-1.7616]])\n","Gradient for b: tensor(-0.8808)\n"]}],"source":["import torch\n","\n","# Input (manual)\n","X = torch.tensor([[0.5, -1.5, 2.0]], dtype=torch.float32)\n","\n","# Weights and bias (manual, requires_grad for backprop)\n","W = torch.tensor([[0.2], [0.8], [-0.5]], dtype=torch.float32, requires_grad=True)\n","b = torch.tensor(0.1, dtype=torch.float32, requires_grad=True)\n","\n","# z = XW + b\n","z = torch.mm(X, W) + b\n","\n","# Sigmoid\n","a = torch.sigmoid(z)\n","\n","# True label\n","y_true = torch.tensor([[1.0]], dtype=torch.float32)\n","\n","# Manually calculating loss\n","epsilon = 1e-7\n","loss = -(y_true * torch.log(a + epsilon) + (1 - y_true) * torch.log(1 - a + epsilon))\n","\n","# Backward pass\n","loss.backward()\n","\n","print(\"\\nPyTorch\")\n","print(\"z:\", z.detach().numpy())\n","print(\"sigmoid(z):\", a.detach().numpy())\n","print(\"Binary Cross-Entropy Loss:\", loss.item())\n","print(\"Gradients for W:\", W.grad)\n","print(\"Gradient for b:\", b.grad)"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}